{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Jti24LGTV09Z",
    "outputId": "681d0f63-ce71-40be-83a1-e56328d5d5e0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from shutil import copy2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Jh6p1jfV3z_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# For process to not allocate entire GPU memory\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9WwP-QYV5Rf"
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = \"./trafficnet_dataset_v1/train/\"\n",
    "TEST_DATA_PATH = \"./trafficnet_dataset_v1/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfGwmspbV6o3"
   },
   "outputs": [],
   "source": [
    "image_files = []\n",
    "labels = []\n",
    "for class_ in os.listdir(TRAIN_DATA_PATH):\n",
    "    class_folder_path = TRAIN_DATA_PATH+class_+\"/\"\n",
    "    for image_file in os.listdir(class_folder_path):\n",
    "        image_files.append(class_folder_path+image_file)\n",
    "        labels.append(class_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vHSHR4RV7kf"
   },
   "outputs": [],
   "source": [
    "train_files, val_files, train_labels, val_labels = train_test_split(image_files, labels, stratify=labels, test_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ZBzZdK3_V87n",
    "outputId": "d66dd175-7ae3-4707-802e-ef48dcf1744e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3101, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files), len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4hvsldWV97f"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"./data_for_training/training/\", exist_ok=True)\n",
    "os.makedirs(\"./data_for_training/validation/\", exist_ok=True)\n",
    "\n",
    "for i, train_file in enumerate(train_files):\n",
    "    os.makedirs(\"./data_for_training/training/\"+train_labels[i]+\"/\", exist_ok=True)\n",
    "    copy2(train_file, \"./data_for_training/training/\"+train_labels[i]+\"/\")\n",
    "\n",
    "for i, val_file in enumerate(val_files):\n",
    "    os.makedirs(\"./data_for_training/validation/\"+val_labels[i]+\"/\", exist_ok=True)\n",
    "    copy2(val_file, \"./data_for_training/validation/\"+val_labels[i]+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ElxOM4wDV_Ln"
   },
   "outputs": [],
   "source": [
    "# example of progressively loading images from file\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# create generator\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "      rotation_range=10,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest', dtype=np.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "j5KWUrP8WB2P",
    "outputId": "2f16bda2-d712-4696-fb92-e548a08eb07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3600 images belonging to 4 classes.\n",
      "Found 800 images belonging to 4 classes.\n",
      "Found 800 images belonging to 4 classes.\n",
      "Batch shape=(128, 128, 128, 3), min=0.000, max=1.000\n"
     ]
    }
   ],
   "source": [
    "# prepare an iterators for each dataset\n",
    "train_it = datagen.flow_from_directory(TRAIN_DATA_PATH, class_mode='categorical', batch_size=128, target_size=(128, 128))\n",
    "val_it = datagen.flow_from_directory(TEST_DATA_PATH, class_mode='categorical', batch_size=128, target_size=(128, 128))\n",
    "test_it = datagen.flow_from_directory('trafficnet_dataset_v1/test/', class_mode='categorical', batch_size=128, target_size=(128, 128))\n",
    "# confirm the iterator works\n",
    "batchX, batchy = train_it.next()\n",
    "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FxcLTeBulreg",
    "outputId": "8d64821f-4212-4b29-da14-31ba3d8ad5e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accident': 0, 'dense_traffic': 1, 'fire': 2, 'sparse_traffic': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_it.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "#Load the VGG model\n",
    "vgg_conv = VGG16(weights=None, include_top=False, input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "2jsemu60XDPF",
    "outputId": "fd0b3e41-7d96-4cb9-a459-4babc8d3b3e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f1b01af1a50> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01af1a90> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01aef750> True float16\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1b01ae4890> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01ae2e90> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b021e4a50> True float16\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1b0195ba90> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b0274ce10> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b021de890> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01bc3d10> True float16\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1b021d20d0> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01fc95d0> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01fc8350> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01dfb810> True float16\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1b01a37750> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b02272bd0> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01982990> True float16\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1b01982b50> True float16\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f1b019a8dd0> True float16\n"
     ]
    }
   ],
   "source": [
    "# Freeze the layers except the last 4 layers\n",
    "for layer in vgg_conv.layers[:-6]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Check the trainable status of the individual layers\n",
    "for layer in vgg_conv.layers:\n",
    "    print(layer, layer.trainable, layer.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "k1Ildt3YXLWv",
    "outputId": "4a1ffad5-446e-443b-9303-37798af13de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 23,662,212\n",
      "Trainable params: 23,662,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    " \n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "model.add(vgg_conv)\n",
    " \n",
    "# Add new layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, activation='relu', kernel_initializer='he_normal', dtype=np.float16))\n",
    "model.add(layers.Dropout(0.01, dtype=np.float16))\n",
    "model.add(layers.Dense(512, activation='relu', kernel_initializer='he_normal', dtype=np.float16))\n",
    "model.add(layers.Dense(64, activation='relu', kernel_initializer='he_normal', dtype=np.float16))\n",
    "model.add(layers.Dense(4, activation='softmax', dtype=np.float16))\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCQuzbDdXN9v"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-3),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyfIg5kkXQJX"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=8, min_lr=0.00000001, verbose=1)\n",
    "call_backs = [reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "zakbZNVXXRSo",
    "outputId": "45d86aec-7d6d-4fda-8f31-c2685485b4fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9000\n",
      "29/28 [==============================] - 20s 673ms/step - loss: 1.4232 - acc: 0.2491 - val_loss: 1.5567 - val_acc: 0.2500\n",
      "Epoch 2/9000\n",
      "29/28 [==============================] - 14s 494ms/step - loss: 1.3871 - acc: 0.2573 - val_loss: 1.5533 - val_acc: 0.2500\n",
      "Epoch 3/9000\n",
      "29/28 [==============================] - 15s 501ms/step - loss: 1.3882 - acc: 0.2512 - val_loss: 1.5537 - val_acc: 0.2500\n",
      "Epoch 4/9000\n",
      "29/28 [==============================] - 15s 511ms/step - loss: 1.3870 - acc: 0.2452 - val_loss: 1.5533 - val_acc: 0.2500\n",
      "Epoch 5/9000\n",
      "29/28 [==============================] - 15s 507ms/step - loss: 1.3870 - acc: 0.2458 - val_loss: 1.5533 - val_acc: 0.2500\n",
      "Epoch 6/9000\n",
      "29/28 [==============================] - 15s 506ms/step - loss: 1.3889 - acc: 0.2426 - val_loss: 1.5550 - val_acc: 0.2500\n",
      "Epoch 7/9000\n",
      " 9/28 [========>.....................] - ETA: 7s - loss: 1.3875 - acc: 0.2179"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-80-fb90b15b3516>\", line 2, in <module>\n",
      "    validation_steps=val_it.samples/val_it.batch_size, verbose=1, callbacks=call_backs, epochs=9000)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1297, in fit_generator\n",
      "    steps_name='steps_per_epoch')\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 265, in model_iteration\n",
      "    batch_outs = batch_function(*batch_data)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 973, in train_on_batch\n",
      "    class_weight=class_weight, reset_metrics=reset_metrics)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 264, in train_on_batch\n",
      "    output_loss_metrics=model._output_loss_metrics)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 311, in train_on_batch\n",
      "    output_loss_metrics=output_loss_metrics))\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 272, in _process_single_batch\n",
      "    model.optimizer.apply_gradients(zip(grads, trainable_weights))\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 441, in apply_gradients\n",
      "    kwargs={\"name\": name})\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1917, in merge_call\n",
      "    return self._merge_call(merge_fn, args, kwargs)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1924, in _merge_call\n",
      "    return merge_fn(self._strategy, *args, **kwargs)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\", line 497, in _distributed_apply\n",
      "    return self._iterations.assign_add(1)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 781, in assign_add\n",
      "    name=name)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py\", line 52, in assign_add_variable_op\n",
      "    value)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/saadzia/anaconda3/envs/tf2_gpu/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 224, in findsource\n",
      "    if not hasattr(object, 'co_firstlineno'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_it, steps_per_epoch=train_it.samples/train_it.batch_size, validation_data=val_it, \\\n",
    "                    validation_steps=val_it.samples/val_it.batch_size, verbose=1, callbacks=call_backs, epochs=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-6HWesrfkfwX"
   },
   "outputs": [],
   "source": [
    "model.save(\"trafficnet_vgg_16_086.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "id": "VOME5C3dkpAB",
    "outputId": "e8c0f604-a6e3-4f8b-e96f-6629b62f24aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 993kB 46.7MB/s eta 0:00:01\n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0731 19:49:34.433693 139890822862720 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ModuleNotFoundError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file with ID 1eEUp0e2mGY6sMuMRLRj3ZhZTKd3IlMvh\n"
     ]
    }
   ],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Create & upload a file.\n",
    "uploaded = drive.CreateFile({'title': 'trafficnet_vgg_16_086.h5'})\n",
    "uploaded.SetContentFile('trafficnet_vgg_16_086.h5')\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TrafficNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
